{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e254e156",
   "metadata": {},
   "source": [
    "# Basic HuggingFace transformer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3757a288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d271f3677dc4ffa85d4d1170dd68163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.5997239947319031}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    revision=\"714eb0f\"\n",
    ")\n",
    "\n",
    "classifier(\"I'm in mood for an ice cream\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc38a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40465c3fca54e68a23a0ce83c19d297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'We need a grownup conversation about why our political economy is killing life on Earth',\n",
       " 'labels': ['politics', 'education', 'business'],\n",
       " 'scores': [0.9821483492851257, 0.00954105332493782, 0.008310540579259396]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Zero shot classification\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "classifier(\n",
    "    \"We need a grownup conversation about why our political economy is killing life on Earth\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "227b9a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099fcf47dd99409799380653fe69a5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: openai-community/gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Today I stand with the people, but tomorrow I may find my voice heard. This will be a time of reckoning. In fact, it will be a time that I will face and understand. I will find the truth behind the lies and the lies of the hypocrites; I will find the truth behind the lies of the ignorant, the infidels, the false prophets and the false leaders. I will find the truth behind the lies of the hypocrites. I will find the truth behind the lies of the hypocrites.\"\\n\\n\"To the wise, with the wisdom of the heart, with the wisdom of the mind, let us pray:\\n\\n\"Behold the great peace of God, the One Truth!\"\\n\\n\"And this peace we have made with the One God, and this peace we have made with the One God alone.\\n\\n\"And this peace we have made with the One God, and this peace we have made with the One God alone.\\n\\n\"And this peace we have made with the One God alone.\\n\\n\"And this peace we have made with the One God alone.\\n\\n\"And this peace we have made with the One God alone.\\n\\n\"And this peace we have made with the One God alone.\\n\\n\"And this peace we have made'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing out text generation\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "generator(\"Today I stand with the people, but tomorrow I may\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b46c5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3305f30a305b4e2c9ca298aae6a5dc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8525319695472717, 'start': 51, 'end': 61, 'answer': 'California'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing out question answering\n",
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Akram and I work as an AI researcher in California\",\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
